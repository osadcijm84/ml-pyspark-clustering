# Лабораторная работа №5: Модель кластеризации на PySpark

## Цель работы
Получить навыки разработки и настройки Spark приложения.

## Описание
Данный репозиторий содержит материалы по лабораторной работе №5, посвященной разработке модели кластеризации на PySpark с использованием алгоритма K-средних. В рамках работы была настроена среда для Spark вычислений, проведена предобработка данных и реализована модель кластеризации.

## Ход работы
1. **Настройка среды для Spark вычислений:** Среда для Spark вычислений была успешно настроена с использованием Docker Compose, включающего Spark Master, Spark Worker и PySpark приложение. Все необходимые зависимости установлены.
2. **Проверка работоспособности компонентов Spark платформы:** Работоспособность компонентов Spark была проверена путем успешного запуска примера WordCount, демонстрирующего базовые операции Spark.
3. **Разработка модели кластеризации на PySpark:** Реализована модель кластеризации на базе алгоритма K-средних. Проведена предобработка данных, включая векторизацию текстовых признаков и масштабирование числовых.
4. **Предобработка данных из Open Food Facts:** Для демонстрации работы модели использован имитированный набор данных Open Food Facts, который по структуре соответствует реальным данным и позволяет продемонстрировать процесс кластеризации.

## Результаты работы
- Отчет о проделанной работе.
- Ссылка на репозиторий GitHub.
- Актуальный дистрибутив модели в zip архиве.

## Автор
Maxim


